{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:32.555377Z","iopub.execute_input":"2024-06-05T22:51:32.555807Z","iopub.status.idle":"2024-06-05T22:51:37.135912Z","shell.execute_reply.started":"2024-06-05T22:51:32.555772Z","shell.execute_reply":"2024-06-05T22:51:37.134961Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.138370Z","iopub.execute_input":"2024-06-05T22:51:37.139331Z","iopub.status.idle":"2024-06-05T22:51:37.145016Z","shell.execute_reply.started":"2024-06-05T22:51:37.139294Z","shell.execute_reply":"2024-06-05T22:51:37.143968Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using cpu device\n","output_type":"stream"}]},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.146409Z","iopub.execute_input":"2024-06-05T22:51:37.146736Z","iopub.status.idle":"2024-06-05T22:51:37.157418Z","shell.execute_reply.started":"2024-06-05T22:51:37.146699Z","shell.execute_reply":"2024-06-05T22:51:37.156452Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = NeuralNetwork().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.159950Z","iopub.execute_input":"2024-06-05T22:51:37.160294Z","iopub.status.idle":"2024-06-05T22:51:37.211179Z","shell.execute_reply.started":"2024-06-05T22:51:37.160269Z","shell.execute_reply":"2024-06-05T22:51:37.210042Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"X = torch.rand(1, 28, 28, device=device)\nlogits = model(X)\npred_probab = nn.Softmax(dim=1)(logits)\ny_pred = pred_probab.argmax(1)\nprint(f\"Predicted class: {y_pred}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.212660Z","iopub.execute_input":"2024-06-05T22:51:37.213498Z","iopub.status.idle":"2024-06-05T22:51:37.270355Z","shell.execute_reply.started":"2024-06-05T22:51:37.213461Z","shell.execute_reply":"2024-06-05T22:51:37.269286Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Predicted class: tensor([5])\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.profiler import profile, record_function, ProfilerActivity","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.271561Z","iopub.execute_input":"2024-06-05T22:51:37.271887Z","iopub.status.idle":"2024-06-05T22:51:37.276476Z","shell.execute_reply.started":"2024-06-05T22:51:37.271860Z","shell.execute_reply":"2024-06-05T22:51:37.275367Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n    with record_function(\"model_inference\"):\n        model(X)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.277819Z","iopub.execute_input":"2024-06-05T22:51:37.278205Z","iopub.status.idle":"2024-06-05T22:51:37.306385Z","shell.execute_reply.started":"2024-06-05T22:51:37.278172Z","shell.execute_reply":"2024-06-05T22:51:37.305226Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"STAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.307659Z","iopub.execute_input":"2024-06-05T22:51:37.307970Z","iopub.status.idle":"2024-06-05T22:51:37.316455Z","shell.execute_reply.started":"2024-06-05T22:51:37.307944Z","shell.execute_reply":"2024-06-05T22:51:37.315421Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n       model_inference        37.73%       3.025ms       100.00%       8.018ms       8.018ms             1  \n          aten::linear        11.11%     891.000us        30.71%       2.462ms     820.667us             3  \n         aten::flatten        22.35%       1.792ms        22.55%       1.808ms       1.808ms             1  \n           aten::addmm        18.18%       1.458ms        18.73%       1.502ms     500.667us             3  \n            aten::relu         8.72%     699.000us         9.02%     723.000us     361.500us             2  \n               aten::t         0.46%      37.000us         0.86%      69.000us      23.000us             3  \n       aten::transpose         0.31%      25.000us         0.40%      32.000us      10.667us             3  \n       aten::clamp_min         0.30%      24.000us         0.30%      24.000us      12.000us             2  \n          aten::expand         0.24%      19.000us         0.27%      22.000us       7.333us             3  \n           aten::copy_         0.26%      21.000us         0.26%      21.000us       7.000us             3  \n----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 8.018ms\n\n","output_type":"stream"}]},{"cell_type":"code","source":"with profile(activities=[\n        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n    with record_function(\"model_inference\"):\n        model(X)\n\nprint(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.317708Z","iopub.execute_input":"2024-06-05T22:51:37.318017Z","iopub.status.idle":"2024-06-05T22:51:37.339180Z","shell.execute_reply.started":"2024-06-05T22:51:37.317992Z","shell.execute_reply":"2024-06-05T22:51:37.338206Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n       model_inference        55.44%     622.000us       100.00%       1.122ms       1.122ms             1  \n         aten::flatten         1.25%      14.000us         2.85%      32.000us      32.000us             1  \n            aten::view         1.60%      18.000us         1.60%      18.000us      18.000us             1  \n          aten::linear         2.05%      23.000us        36.81%     413.000us     137.667us             3  \n               aten::t         3.03%      34.000us         5.17%      58.000us      19.333us             3  \n       aten::transpose         1.69%      19.000us         2.14%      24.000us       8.000us             3  \n      aten::as_strided         0.53%       6.000us         0.53%       6.000us       1.000us             6  \n           aten::addmm        24.42%     274.000us        29.59%     332.000us     110.667us             3  \n          aten::expand         2.94%      33.000us         3.03%      34.000us      11.333us             3  \n           aten::copy_         2.05%      23.000us         2.05%      23.000us       7.667us             3  \n----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 1.122ms\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/autograd/profiler.py:255: UserWarning: CUDA is not available, disabling CUDA profiling\n  warn(\"CUDA is not available, disabling CUDA profiling\")\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n","output_type":"stream"}]},{"cell_type":"code","source":"with profile(activities=[ProfilerActivity.CPU],\n        profile_memory=True, record_shapes=True) as prof:\n    model(X)\n\nprint(prof.key_averages())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.341539Z","iopub.execute_input":"2024-06-05T22:51:37.342304Z","iopub.status.idle":"2024-06-05T22:51:37.357013Z","shell.execute_reply.started":"2024-06-05T22:51:37.342275Z","shell.execute_reply":"2024-06-05T22:51:37.355890Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n         aten::flatten         2.15%      10.000us         4.94%      23.000us      23.000us           0 b           0 b             1  \n            aten::view         2.79%      13.000us         2.79%      13.000us      13.000us           0 b           0 b             1  \n          aten::linear         3.65%      17.000us        86.27%     402.000us     134.000us       4.04 Kb           0 b             3  \n               aten::t         6.44%      30.000us        10.94%      51.000us      17.000us           0 b           0 b             3  \n       aten::transpose         3.43%      16.000us         4.51%      21.000us       7.000us           0 b           0 b             3  \n      aten::as_strided         1.07%       5.000us         1.07%       5.000us       0.833us           0 b           0 b             6  \n           aten::addmm        65.88%     307.000us        71.67%     334.000us     111.333us       4.04 Kb       4.04 Kb             3  \n          aten::expand         2.36%      11.000us         2.36%      11.000us       3.667us           0 b           0 b             3  \n           aten::copy_         3.43%      16.000us         3.43%      16.000us       5.333us           0 b           0 b             3  \n    aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             6  \n            aten::relu         4.94%      23.000us         8.80%      41.000us      20.500us       4.00 Kb           0 b             2  \n       aten::clamp_min         3.86%      18.000us         3.86%      18.000us       9.000us       4.00 Kb       4.00 Kb             2  \n              [memory]         0.00%       0.000us         0.00%       0.000us       0.000us      -8.04 Kb      -8.04 Kb             5  \n----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 466.000us\n\n","output_type":"stream"},{"name":"stderr","text":"STAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-06-05 22:51:37 33:33 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n","output_type":"stream"}]},{"cell_type":"code","source":"m=1024\nn=4096\nk=1\n\nprint((m*n*k)/(m*n+n*k+k*m))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T22:51:37.358150Z","iopub.execute_input":"2024-06-05T22:51:37.358448Z","iopub.status.idle":"2024-06-05T22:51:37.365137Z","shell.execute_reply.started":"2024-06-05T22:51:37.358424Z","shell.execute_reply":"2024-06-05T22:51:37.363956Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"0.9987807851743478\n","output_type":"stream"}]}]}